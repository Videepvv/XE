{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utt_encoding import UtteranceEncoding\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cos_sim\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_prop(dp_content):\n",
    "    dp_content = dp_content.replace(\"!=\", \"does not equal\").replace(\"=\", \"equals\").\\\n",
    "    replace(\"<\", \"is less than\").replace(\">\", \"is more than\").\\\n",
    "    replace(\"+\", \"plus\").replace(\"10\", \"ten\").replace(\"20\", \"twenty\").replace(\"30\", \"thirty\").\\\n",
    "    replace(\"40\", \"forty\").replace(\"50\",\"fifty\").replace(\"red\", \"red block\").replace(\"blue\", \"blue block\").\\\n",
    "    replace(\"yellow\", \"yellow block\").replace(\"purple\", \"purple block\").replace(\"green\", \"green block\")\n",
    "    return dp_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unstring_prop(dp_content):\n",
    "    dp_content = dp_content.replace(\"equals\",\"=\").replace(\"does not equal\",\"!=\").\\\n",
    "    replace(\"is less than\",\"<\").replace(\"is more than\",\">\").\\\n",
    "    replace(\"plus\",\"+\").replace(\"ten\",\"10\").replace(\"twenty\",\"20\").replace(\"thirty\",\"30\").\\\n",
    "    replace(\"forty\",\"40\").replace(\"fifty\",\"50\").replace(\" block\",\"\")\n",
    "    return dp_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "props = list(pd.read_csv(\"NormalizedList.csv\")[\"Propositions\"])\n",
    "for id, prop in enumerate(props):\n",
    "    props[id] = string_prop(prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterance_encoder = UtteranceEncoding(props)\n",
    "clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['red', 'blue', 'green', 'purple', 'yellow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(common_ground, actual_common_ground):\n",
    "    # Split by ',' and strip whitespace from each element\n",
    "    common_ground_elements = set([element.strip() for element in common_ground.split(',')])\n",
    "    actual_common_ground_elements = set([element.strip() for element in actual_common_ground.split(',')])\n",
    "    # Calculate intersection and union\n",
    "    intersection = common_ground_elements & actual_common_ground_elements\n",
    "    union = common_ground_elements | actual_common_ground_elements\n",
    "    # Calculate IoU\n",
    "    iou = len(intersection) / len(union) if union else 0\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "top1 = []\n",
    "top3 = []\n",
    "topmax = []\n",
    "iou = []\n",
    "acc_1, acc_3, acc_top_max, acc_all = 0, 0, 0, 0\n",
    "jacc_1, jacc_3, jacc_top_max, jacc_all =[], [], [], []\n",
    "data_file = pd.read_csv(\"preprocessedTrainingData.csv\")\n",
    "data_file = data_file[data_file[\"Label\"]==1]\n",
    "spreadsheet = pd.DataFrame()\n",
    "\n",
    "for row_id, utterance in enumerate(data_file[\"Transcript\"]):\n",
    "    selected_colors = []\n",
    "    for color in colors:\n",
    "        if color in utterance.lower():\n",
    "            selected_colors.append(color)\n",
    "    tokenized_text, seq_embedding, pooled_embedding, hidden_states = \\\n",
    "                            utterance_encoder.get_sentence_embedding(utterance,\n",
    "                            utterance_encoder.bert_base_uncased_tokenizer,\n",
    "                            utterance_encoder.bert_base_uncased_model)\n",
    "    token_embeddings = torch.squeeze(torch.stack(hidden_states, dim=0), dim=1).permute(1,0,2)\n",
    "    sum_embeddings = utterance_encoder.get_token_embeddings(token_embeddings, 4)\n",
    "    utterance_embedding = torch.mean(torch.stack(sum_embeddings[:-1]),axis=0)\n",
    "    similarities = []\n",
    "    for prop in utterance_encoder.prop_embs:\n",
    "        # for color in selected_colors:\n",
    "        #     if color in prop:\n",
    "                similarities.append(cos_sim(utterance_embedding.reshape(1,-1),\\\n",
    "                    utterance_encoder.prop_embs[prop].reshape(1,-1))[0][0])\n",
    "    # print(np.max(np.array(similarities)),utterance_encoder.props[np.argmax(np.array(similarities))])\n",
    "    true_prop = data_file.iloc[row_id][\"Common Ground\"]\n",
    "    # Top 1 acc\n",
    "    dp_content = utterance_encoder.props[np.argmax(np.array(similarities))]\n",
    "    dp_content = unstring_prop(dp_content)\n",
    "    if dp_content == true_prop:\n",
    "        acc_1 += 1\n",
    "        top1.append(row_id)\n",
    "    iou.append(calculate_iou(dp_content, true_prop))\n",
    "\n",
    "    # Top 3 acc\n",
    "    for prop_3 in np.array(similarities).argsort()[::-1][:3]:\n",
    "        dp_content = utterance_encoder.props[prop_3]\n",
    "        dp_content = unstring_prop(dp_content)\n",
    "        if dp_content == true_prop:\n",
    "            acc_3 += 1\n",
    "            top3.append(row_id)\n",
    "    # tmp = {\"Utt_id\":0, \"Transcript\":\"\", \"Ground truth\":\"\", \"Correct\":0, \"Top 1 prop\":\"\", \"Top 1 cosim\":0}\n",
    "    # Top 5 acc\n",
    "    tmp = {}\n",
    "    tmp[\"Utt_id\"] = row_id\n",
    "    tmp[\"Transcript\"] = utterance\n",
    "    tmp[\"Ground truth\"] = true_prop\n",
    "    tmp[\"Correct\"] = 0\n",
    "\n",
    "    old = acc_top_max\n",
    "    top_max = 10\n",
    "    for i, prop_top_max in enumerate(np.array(similarities).argsort()[::-1][:top_max]):\n",
    "        dp_content = utterance_encoder.props[prop_top_max]\n",
    "        dp_content = unstring_prop(dp_content)\n",
    "        if dp_content == true_prop:\n",
    "            acc_top_max += 1\n",
    "            topmax.append(row_id)\n",
    "            tmp[\"Correct\"] = i+1\n",
    "        tmp[\"Top \"+ str(i+1)+ \" prop\"] = dp_content\n",
    "        tmp[\"Top \"+ str(i+1)+ \" cosim\"] = np.sort(np.array(similarities))[::-1][:top_max][i]\n",
    "        # add to tmp df the oracle transcript, the 5 DPs and their cosines\n",
    "        tmp[\"Top \"+ str(i+1)+ \" IOU\"] = calculate_iou(dp_content, true_prop)\n",
    "    # add all metrics to corresponding utt \n",
    "    df_dictionary = pd.DataFrame([tmp])\n",
    "    spreadsheet = pd.concat([spreadsheet, df_dictionary], ignore_index=True)\n",
    "    if acc_top_max == old:\n",
    "        l.append(row_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spreadsheet.to_csv(\"DP_bert_10.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 6, 12, 30, 49, 50, 55, 57, 64, 67, 91, 110]\n",
      "[0, 1, 3, 6, 12, 15, 21, 30, 32, 37, 49, 50, 55, 57, 64, 65, 67, 86, 91, 92, 94, 110]\n",
      "[0, 1, 3, 6, 8, 9, 12, 15, 20, 21, 30, 32, 37, 42, 49, 50, 52, 55, 57, 59, 64, 65, 67, 74, 83, 86, 88, 89, 91, 92, 94, 102, 104, 107, 108, 110, 117, 125]\n"
     ]
    }
   ],
   "source": [
    "print(top1)\n",
    "print(top3)\n",
    "print(topmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "22\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "print(acc_1)\n",
    "print(acc_3)\n",
    "print(acc_top_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12427821522309711"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(iou)/len(iou)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
